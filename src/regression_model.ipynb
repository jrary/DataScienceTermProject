{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pygam import LinearGAM, s, f\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('assets/output/featureSelectionResult.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df.drop(['date', 'visitor'], axis=1)\n",
    "y = df['visitor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 25501186.226291727\n",
      "R^2 Score: 0.4040373650822504\n"
     ]
    }
   ],
   "source": [
    "# Data Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Add Constant Column\n",
    "X_train = sm.add_constant(X_train)\n",
    "X_test = sm.add_constant(X_test)\n",
    "\n",
    "# Create and learn GAM models\n",
    "# Returns: Instance of the LinearGAM class\n",
    "gam = LinearGAM()\n",
    "gam.fit(X_train, y_train)\n",
    "\n",
    "# Prediction of test data\n",
    "y_pred = gam.predict(X_test)\n",
    "\n",
    "# Evaluation: Calculating the Mean Square Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Evaluation: Calculating the coefficient of determination (R^2)\n",
    "r2_gam = r2_score(y_test, y_pred)\n",
    "print(f\"R^2 Score: {r2_gam}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2009-01-03'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# Add polynomial characteristics\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# Creates an instance of the PolynomialFeatures class.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m# Parameters - degree: The degree of the polynomial features to be generated. It determines the maximum degree of monomials in the output array.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m poly \u001b[39m=\u001b[39m PolynomialFeatures(degree\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m X_poly \u001b[39m=\u001b[39m poly\u001b[39m.\u001b[39;49mfit_transform(X)\n\u001b[1;32m     19\u001b[0m \u001b[39m# Data Split\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39m# Parameters:\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39m# - X_poly: The input features (in polynomial form) used for splitting into train and test sets.\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39m# - y: The target variable used for splitting into train and test sets.\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39m# - test_size: The proportion of the dataset to include in the test split. It should be a float value between 0.0 and 1.0.\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39m# - random_state: Determines the random seed for the shuffling of the dataset before splitting. It ensures reproducibility of the split.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X_poly, y, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/sklearn/base.py:878\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    875\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    877\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    879\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    880\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    881\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/sklearn/preprocessing/_polynomial.py:252\u001b[0m, in \u001b[0;36mPolynomialFeatures.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[39mCompute number of output features.\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39m    Fitted transformer.\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m--> 252\u001b[0m _, n_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39mshape\n\u001b[1;32m    254\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdegree, Integral):\n\u001b[1;32m    255\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdegree \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minclude_bias:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/sklearn/base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    564\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 565\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    566\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    567\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/sklearn/utils/validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    877\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    878\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 879\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[1;32m    880\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[1;32m    881\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    882\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    883\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/sklearn/utils/_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    182\u001b[0m     xp, _ \u001b[39m=\u001b[39m get_namespace(array)\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnumpy.array_api\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[1;32m    184\u001b[0m     \u001b[39m# Use NumPy API to support order\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array, copy\u001b[39m=\u001b[39mcopy)\n\u001b[1;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/generic.py:2070\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2069\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m-> 2070\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '2009-01-03'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# data load\n",
    "df = pd.read_csv('assets/output/featureSelectionResult.csv')\n",
    "df['visitor'] = df['visitor'].str.replace(',', '').astype(int)\n",
    "\n",
    "# Features and Target Split\n",
    "X = df.drop(['visitor'], axis=1)\n",
    "y = df['visitor']\n",
    "\n",
    "# Add polynomial characteristics\n",
    "# Creates an instance of the PolynomialFeatures class.\n",
    "# Parameters - degree: The degree of the polynomial features to be generated. It determines the maximum degree of monomials in the output array.\n",
    "poly = PolynomialFeatures(degree=4)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# Data Split\n",
    "# Parameters:\n",
    "# - X_poly: The input features (in polynomial form) used for splitting into train and test sets.\n",
    "# - y: The target variable used for splitting into train and test sets.\n",
    "# - test_size: The proportion of the dataset to include in the test split. It should be a float value between 0.0 and 1.0.\n",
    "# - random_state: Determines the random seed for the shuffling of the dataset before splitting. It ensures reproducibility of the split.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model Learning\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prediction of test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluation: Calculating the Mean Square Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Evaluation: Calculating the coefficient of determination (R^2)\n",
    "r2_lin = r2_score(X_test, y_test)\n",
    "print(f\"R^2 Score: {r2_lin}\")\n",
    "\n",
    "score = model.score(X_test, y_test)\n",
    "print(f\"score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.57 PiB for an array with shape (2468, 89356415775) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12300\\3150709361.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# 다항 특성 추가\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mpoly\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPolynomialFeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdegree\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mX_poly\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# 데이터 분할\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    850\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    851\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 852\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    853\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    419\u001b[0m             \u001b[1;31m# Do as if _min_degree = 0 and cut down array after the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m             \u001b[1;31m# computation, i.e. use _n_out_full instead of n_output_features_.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m             XP = np.empty(\n\u001b[0m\u001b[0;32m    422\u001b[0m                 \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_out_full\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m             )\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.57 PiB for an array with shape (2468, 89356415775) and data type float64"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data load\n",
    "data = pd.read_csv('assets/output/featureSelectionResult.csv')\n",
    "\n",
    "# Create a k-fold object that divides data into k subsets\n",
    "k = 5  # Set the value of k in k-fold cross-validation\n",
    "\n",
    "# Parameters:\n",
    "# - n_splits: The number of folds (subsets) to split the data into. It determines the number of times the cross-validation process will be performed.\n",
    "# - shuffle: Determines whether to shuffle the data before splitting it into folds. If True, the data will be shuffled randomly.\n",
    "# - random_state: Determines the random seed for shuffling the data if `shuffle` is set to True. It ensures reproducibility of the shuffling.\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Features and Target Split\n",
    "X = df.drop(['date', 'visitor'], axis=1)\n",
    "y = df['visitor']\n",
    "\n",
    "# Add polynomial characteristics\n",
    "# Creates an instance of the PolynomialFeatures class.\n",
    "# Parameters - degree: The degree of the polynomial features to be generated. It determines the maximum degree of monomials in the output array.\n",
    "poly = PolynomialFeatures(degree=7)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# Data Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=42)\n",
    "model = LinearRegression()\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "mse_scores = []\n",
    "score_arr = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_poly):\n",
    "    # Split training set, test set\n",
    "    X_train, X_test = X_poly[train_index], X_poly[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting test Sets\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate the mean square error of the test set\n",
    "    # Parameters:\n",
    "    # - y_test: The true target values from the test set.\n",
    "    # - y_pred: The predicted target values corresponding to the test set.\n",
    "\n",
    "    # Returns:\n",
    "    # The mean squared error (MSE) between the true target values and the predicted target values.\n",
    "    # MSE is a measure of the average squared difference between the predicted and true values, providing an overall assessment of the model's performance.\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    score = model.score(X_test, y_test)\n",
    "\n",
    "    # for caculating mean score, appending\n",
    "    score_arr.append(score)\n",
    "    mse_scores.append(mse)\n",
    "\n",
    "# Calculate the mean MSE of k-fold cross-validation, and score\n",
    "mean_mse = np.mean(mse_scores)\n",
    "mean_score = np.mean(score_arr)\n",
    "\n",
    "print(mean_score)\n",
    "print(mean_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree: 2, K: 2, Score: -1.4453290120723794\n",
      "Degree: 2, K: 3, Score: -1.5500444006824747\n",
      "Degree: 2, K: 4, Score: -2.5698713980269794\n",
      "Degree: 2, K: 5, Score: -2.269611424698757\n",
      "Degree: 2, K: 6, Score: -2.42114484270842\n",
      "Degree: 2, K: 7, Score: -2.6019427159343893\n",
      "Degree: 2, K: 8, Score: -2.516380485753828\n",
      "Degree: 2, K: 9, Score: -2.6433477140108903\n",
      "Degree: 2, K: 10, Score: -2.6515864031634773\n",
      "Degree: 3, K: 2, Score: -2.744040871735411\n",
      "Degree: 3, K: 3, Score: -0.7795631180669202\n",
      "Degree: 3, K: 4, Score: -3.998184533635186\n",
      "Degree: 3, K: 5, Score: -2.043004799453641\n",
      "Degree: 3, K: 6, Score: -5.100733056045133\n",
      "Degree: 3, K: 7, Score: -1.7761296344846766\n",
      "Degree: 3, K: 8, Score: -1.6075872820962571\n",
      "Degree: 3, K: 9, Score: -2.8519922668611106\n",
      "Degree: 3, K: 10, Score: -2.761721710945369\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 173. GiB for an array with shape (2468, 9381251) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18408\\3129665777.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[0mmax_k\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m \u001b[0mbest_degree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_k\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_best_degree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_degree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_degree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Best degree: {best_degree}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18408\\3129665777.py\u001b[0m in \u001b[0;36mfind_best_degree\u001b[1;34m(X, y, min_degree, max_degree, min_k, max_k, random_state)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m# 다항 특성 추가\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mpoly\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPolynomialFeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdegree\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdegree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mX_poly\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_k\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    850\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    851\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 852\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    853\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    419\u001b[0m             \u001b[1;31m# Do as if _min_degree = 0 and cut down array after the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m             \u001b[1;31m# computation, i.e. use _n_out_full instead of n_output_features_.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m             XP = np.empty(\n\u001b[0m\u001b[0;32m    422\u001b[0m                 \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_out_full\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m             )\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 173. GiB for an array with shape (2468, 9381251) and data type float64"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np\n",
    "\n",
    "# Loading data\n",
    "df = pd.read_csv('assets/output/featureSelectionResult.csv')\n",
    "\n",
    "# Methods for finding the best results by using K-fold in the polynomial regression, changing the degree and K\n",
    "# Parameters:\n",
    "    # X: The input features used for the regression analysis.\n",
    "    # y: The target variable.\n",
    "    # min_degree: The minimum degree of polynomial features to consider.\n",
    "    # max_degree: The maximum degree of polynomial features to consider.\n",
    "    # min_k: The minimum number of folds (subsets) for cross-validation.\n",
    "    # max_k: The maximum number of folds (subsets) for cross-validation.\n",
    "    # random_state: Determines the random seed for shuffling the data and cross-validation. It ensures reproducibility of the results.\n",
    "# Returns:\n",
    "    # best_degree: The degree value that yielded the best score.\n",
    "    # best_score: The highest score obtained among different degree and k combinations.\n",
    "    # best_k: The k value that yielded the best score.\n",
    "def find_best_degree(X, y, min_degree, max_degree, min_k, max_k, random_state=42):\n",
    "    results = []\n",
    "    best_degree = None\n",
    "    best_score = -np.inf\n",
    "    best_k = None\n",
    "\n",
    "    for degree in range(min_degree, max_degree+1):\n",
    "        # Add polynomial characteristics\n",
    "        poly = PolynomialFeatures(degree=degree)\n",
    "        X_poly = poly.fit_transform(X)\n",
    "\n",
    "        for k in range(min_k, max_k+1):\n",
    "            model = LinearRegression()\n",
    "\n",
    "            # Perform k-fold cross-validation\n",
    "            # Parameters:\n",
    "                # - n_splits: The number of folds (subsets) to split the data into. It determines the number of times the cross-validation process will be performed.\n",
    "                # - shuffle: Determines whether to shuffle the data before splitting it into folds. If True, the data will be shuffled randomly.\n",
    "                # - random_state: Determines the random seed for shuffling the data if `shuffle` is set to True. It ensures reproducibility of the shuffling.\n",
    "            kf = KFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "            score_arr = []\n",
    "            mse_scores = []\n",
    "\n",
    "            for train_index, test_index in kf.split(X_poly):\n",
    "                # Split training set, test set\n",
    "                X_train, X_test = X_poly[train_index], X_poly[test_index]\n",
    "                y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "                model.fit(X_train, y_train)\n",
    "\n",
    "                # Calculating the score for the test set\n",
    "                score = model.score(X_test, y_test)\n",
    "                score_arr.append(score)\n",
    "\n",
    "                # Calculating the mean squared error (MSE) for the test set\n",
    "                mse = mean_squared_error(y_test, y_pred)\n",
    "                mse_scores.append(mse)\n",
    "\n",
    "                print(f\"Degree: {degree}, K: {k}, MSE: {mse}\")\n",
    "\n",
    "            # Calculating the Average Score\n",
    "            mean_score = np.mean(score_arr)\n",
    "            results.append((degree, k, mean_score))\n",
    "            print(f\"Degree: {degree}, K: {k}, Score: {mean_score}\")\n",
    "\n",
    "            # Update if the current degree and k values are higher than the highest score\n",
    "            if mean_score > best_score:\n",
    "                best_degree = degree\n",
    "                best_score = mean_score\n",
    "                best_k = k\n",
    "\n",
    "    return best_degree, best_score, best_k, mse_scores\n",
    "\n",
    "X = df.drop(['date', 'visitor'], axis=1)\n",
    "y = df['visitor']\n",
    "\n",
    "# Define the minimum and maximum degrees to consider.\n",
    "min_degree = 2\n",
    "max_degree = 6\n",
    "min_k = 2\n",
    "max_k = 10\n",
    "\n",
    "# This function is expected to return the best degree, score, and k value based on the provided ranges.\n",
    "best_degree, best_score, best_k = find_best_degree(X, y, min_degree, max_degree, min_k, max_k)\n",
    "\n",
    "print(f\"Best degree: {best_degree}\")\n",
    "print(f\"Best score: {best_score}\")\n",
    "print(f\"Best k: {best_k}\")\n",
    "print(f\"Average MSE scores: {np.mean(mse_scores)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
