{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pygam import LinearGAM, s, f\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "df = pd.read_csv('assets/output/preprocessedDataset.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# df_temp = df.drop('date', axis=1)\n",
    "# df_temp['visitor'] = df_temp['visitor'].str.replace(',', '')\n",
    "# df_temp['visitor'] = df_temp['visitor'].astype(int)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "X = df.drop(['date', 'visitor'], axis=1)\n",
    "y = df['visitor']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# # 데이터 분할\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "#\n",
    "# # 모델 정의\n",
    "# gam = LinearGAM()\n",
    "#\n",
    "# # 하이퍼파라미터 그리드 설정\n",
    "# param_grid = {\n",
    "#     'lam': np.arange(0.1, 1.1, 0.1),\n",
    "#     'n_splines': np.arange(10, 31, 10),\n",
    "#     'degree': np.arange(1, 4)\n",
    "# }\n",
    "#\n",
    "# # 그리드 서치 객체 생성\n",
    "# grid_search = GridSearchCV(gam, param_grid=param_grid, cv=5, return_train_score=True)\n",
    "#\n",
    "# # 그리드 서치 수행\n",
    "# grid_search.fit(X_train, y_train)\n",
    "#\n",
    "# # 최적 매개변수 조합 및 최적 모델 출력\n",
    "# best_params = grid_search.best_params_\n",
    "# print(\"Best Parameters:\", best_params)\n",
    "# best_model = grid_search.best_estimator_\n",
    "# print(\"Best Model:\", best_model)\n",
    "#\n",
    "# # 테스트 데이터에 대한 예측\n",
    "# y_pred = best_model.predict(X_test)\n",
    "#\n",
    "# # 평가: 평균 제곱 오차 계산\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# print(f\"Mean Squared Error: {mse}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "selected_feat = ['sulfur_dioxide_min', 'carbon_monoxide_max', 'ozone_max', 'nitrogen_dioxide_max', 'fine_dust_pm10_max',                 'rainfall_max', 'probability of precipitation_min', 'humidity_min', 'highest temperature_max',                 'lowest temperature_min', 'wind speed_median', 'weekday_1.0' ,'weekday_2.0', 'weekday_3.0','weekday_4.0', 'weekday_5.0', 'weekday_6.0', 'weekday_7.0',  'visitor']\n",
    "df_selected = df[selected_feat]\n",
    "\n",
    "X = df_selected.drop(['visitor'], axis=1)\n",
    "y = df_selected['visitor']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 81659152.28296266\n",
      "R^2 Score: 0.2735618808369892\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "df = pd.read_csv('assets/output/preprocessedDataset.csv')\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# 상수 열 추가\n",
    "X_train = sm.add_constant(X_train)\n",
    "X_test = sm.add_constant(X_test)\n",
    "\n",
    "# GAM 모델 생성 및 학습\n",
    "gam = LinearGAM()\n",
    "gam.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred = gam.predict(X_test)\n",
    "\n",
    "# 평가: 평균 제곱 오차 계산\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# 평가: 결정 계수(R^2) 계산\n",
    "r2_gam = r2_score(y_test, y_pred)\n",
    "print(f\"R^2 Score: {r2_gam}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 2: Mean Score (R^2) = 0.2767639462081313\n",
      "K = 3: Mean Score (R^2) = 0.2790797291775392\n",
      "K = 4: Mean Score (R^2) = 0.2797201624702008\n",
      "K = 5: Mean Score (R^2) = 0.2940826127164266\n",
      "K = 6: Mean Score (R^2) = 0.2894861985898094\n",
      "K = 7: Mean Score (R^2) = 0.27942148341389056\n",
      "K = 8: Mean Score (R^2) = 0.2893379078649954\n",
      "K = 9: Mean Score (R^2) = 0.29257876306378666\n",
      "K = 10: Mean Score (R^2) = 0.29479380895060625\n",
      "Best K: 10\n",
      "Best Score: 0.29479380895060625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Features와 Target 분리\n",
    "X = df_selected.drop(['visitor'], axis=1)\n",
    "y = df_selected['visitor']\n",
    "\n",
    "# 모델 학습 및 평가\n",
    "best_score = float('-inf')\n",
    "best_k = None\n",
    "\n",
    "for k in range(2, 11):  # Try different values of k from 2 to 10\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    mse_scores = []\n",
    "    score_arr = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        model = LinearGAM()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mse_scores.append(mse)\n",
    "\n",
    "        score = model.score(X_test, y_test)\n",
    "        score_arr.append(score)\n",
    "\n",
    "    mean_score = np.mean(score_arr)\n",
    "\n",
    "    if mean_score > best_score:\n",
    "        best_score = mean_score\n",
    "        best_k = k\n",
    "\n",
    "    print(f\"K = {k}: Mean Score (R^2) = {mean_score}\")\n",
    "\n",
    "print(f\"Best K: {best_k}\")\n",
    "print(f\"Best Score: {best_score}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 914723536.2566957\n",
      "score: -8.072517541815914\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 데이터 로드\n",
    "data = pd.read_csv('assets/output/preprocessedDataset.csv')\n",
    "\n",
    "# Features와 Target 분리\n",
    "X = df_selected.drop(['visitor'], axis=1)\n",
    "y = df_selected['visitor']\n",
    "\n",
    "# 다항 특성 추가\n",
    "poly = PolynomialFeatures(degree=4)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 모델 학습\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 평가: 평균 제곱 오차 계산\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# # 평가: 결정 계수(R^2) 계산\n",
    "# r2_lin = r2_score(X_test, y_test)\n",
    "# print(f\"R^2 Score: {r2_lin}\")\n",
    "\n",
    "score = model.score(X_test, y_test)\n",
    "print(f\"score: {score}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_12988\\2899822604.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     36\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     37\u001B[0m     \u001B[1;31m# 모델 학습\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 38\u001B[1;33m     \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     39\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     40\u001B[0m     \u001B[1;31m# 검증 세트 예측\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    716\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_residues\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvstack\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mout\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mouts\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    717\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 718\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcoef_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_residues\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrank_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msingular_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlinalg\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlstsq\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    719\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcoef_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcoef_\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mT\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    720\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_basic.py\u001B[0m in \u001B[0;36mlstsq\u001B[1;34m(a, b, cond, overwrite_a, overwrite_b, check_finite, lapack_driver)\u001B[0m\n\u001B[0;32m   1211\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mreal_data\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1212\u001B[0m                 \u001B[0mlwork\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0miwork\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_compute_lwork\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlapack_lwork\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mm\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnrhs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcond\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1213\u001B[1;33m                 x, s, rank, info = lapack_func(a1, b1, lwork,\n\u001B[0m\u001B[0;32m   1214\u001B[0m                                                iwork, cond, False, False)\n\u001B[0;32m   1215\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# complex data\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드\n",
    "data = pd.read_csv('assets/output/preprocessedDataset.csv')\n",
    "\n",
    "# 데이터를 k개의 부분집합으로 나누는 k-fold 객체 생성\n",
    "k = 5  # k-fold 교차 검증에서의 k 값 설정\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Features와 Target 분리\n",
    "X = df_selected.drop(['visitor'], axis=1)\n",
    "y = df_selected['visitor']\n",
    "\n",
    "# 다항 특성 추가\n",
    "poly = PolynomialFeatures(degree=7)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 모델 학습\n",
    "model = LinearRegression()\n",
    "\n",
    "# k-fold 교차 검증 수행\n",
    "mse_scores = []  # 각 fold에서의 평균 제곱 오차(MSE)를 저장할 리스트\n",
    "score_arr = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_poly):\n",
    "    # 훈련 세트, 검증 세트 나누기\n",
    "    X_train, X_test = X_poly[train_index], X_poly[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # 모델 학습\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 검증 세트 예측\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # 검증 세트의 평균 제곱 오차 계산\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    score = model.score(X_test, y_test)\n",
    "    score_arr.append(score)\n",
    "    mse_scores.append(mse)\n",
    "\n",
    "# k-fold 교차 검증의 평균 MSE 계산\n",
    "mean_mse = np.mean(mse_scores)\n",
    "mean_score = np.mean(score_arr)\n",
    "\n",
    "print(mean_score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_12988\\1593033529.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     40\u001B[0m \u001B[0mmax_degree\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m8\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     41\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 42\u001B[1;33m \u001B[0mresults\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfind_best_degree\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmin_degree\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmax_degree\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     43\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     44\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mdegree\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mscore\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mresults\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_12988\\1593033529.py\u001B[0m in \u001B[0;36mfind_best_degree\u001B[1;34m(X, y, min_degree, max_degree, k, random_state)\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m             \u001B[1;31m# 모델 학습\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 22\u001B[1;33m             \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     23\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     24\u001B[0m             \u001B[1;31m# 검증 세트의 점수 계산\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    716\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_residues\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvstack\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mout\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mouts\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    717\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 718\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcoef_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_residues\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrank_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msingular_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlinalg\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlstsq\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    719\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcoef_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcoef_\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mT\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    720\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_basic.py\u001B[0m in \u001B[0;36mlstsq\u001B[1;34m(a, b, cond, overwrite_a, overwrite_b, check_finite, lapack_driver)\u001B[0m\n\u001B[0;32m   1211\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mreal_data\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1212\u001B[0m                 \u001B[0mlwork\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0miwork\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_compute_lwork\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlapack_lwork\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mm\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnrhs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcond\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1213\u001B[1;33m                 x, s, rank, info = lapack_func(a1, b1, lwork,\n\u001B[0m\u001B[0;32m   1214\u001B[0m                                                iwork, cond, False, False)\n\u001B[0;32m   1215\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# complex data\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "def find_best_degree(X, y, min_degree, max_degree, k=5, random_state=42):\n",
    "    results = []\n",
    "\n",
    "    for degree in range(min_degree, max_degree+1):\n",
    "        # 다항 특성 추가\n",
    "        poly = PolynomialFeatures(degree=degree)\n",
    "        X_poly = poly.fit_transform(X)\n",
    "\n",
    "        # 모델 학습\n",
    "        model = LinearRegression()\n",
    "\n",
    "        # k-fold 교차 검증 수행\n",
    "        kf = KFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "        score_arr = []\n",
    "\n",
    "        for train_index, test_index in kf.split(X_poly):\n",
    "            # 훈련 세트, 검증 세트 나누기\n",
    "            X_train, X_test = X_poly[train_index], X_poly[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            # 모델 학습\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # 검증 세트의 점수 계산\n",
    "            score = model.score(X_test, y_test)\n",
    "            score_arr.append(score)\n",
    "\n",
    "        # 평균 점수 계산\n",
    "        mean_score = np.mean(score_arr)\n",
    "\n",
    "        results.append((degree, mean_score))\n",
    "\n",
    "    return results\n",
    "\n",
    "# Features와 Target 분리\n",
    "X = df_selected.drop(['visitor'], axis=1)\n",
    "y = df_selected['visitor']\n",
    "\n",
    "min_degree = 1\n",
    "max_degree = 8\n",
    "\n",
    "results = find_best_degree(X, y, min_degree, max_degree)\n",
    "\n",
    "for degree, score in results:\n",
    "    print(f\"Degree: {degree}, Score: {score}\")\n",
    "\n",
    "# Find the best degree and score\n",
    "best_degree, best_score = max(results, key=lambda x: x[1])\n",
    "\n",
    "print(f\"Best degree: {best_degree}\")\n",
    "print(f\"Best score: {best_score}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree: 2, K: 2, Score: 0.25895306962871806\n",
      "Degree: 2, K: 3, Score: 0.30658694198072184\n",
      "Degree: 2, K: 4, Score: 0.33032186836426874\n",
      "Degree: 2, K: 5, Score: 0.3252210633940028\n",
      "Degree: 2, K: 6, Score: 0.33256864800334296\n",
      "Degree: 2, K: 7, Score: 0.31723613755822955\n",
      "Degree: 2, K: 8, Score: 0.3330286829975835\n",
      "Degree: 2, K: 9, Score: 0.32793413897224705\n",
      "Degree: 2, K: 10, Score: 0.32056185841589757\n",
      "Degree: 3, K: 2, Score: -172.9441318264206\n",
      "Degree: 3, K: 3, Score: -9.126808162075115\n",
      "Degree: 3, K: 4, Score: -3.8121960824803134\n",
      "Degree: 3, K: 5, Score: -3.0691732020319558\n",
      "Degree: 3, K: 6, Score: -2.8415017242851115\n",
      "Degree: 3, K: 7, Score: -2.462077104034686\n",
      "Degree: 3, K: 8, Score: -2.349916113651603\n",
      "Degree: 3, K: 9, Score: -1.9004101319864988\n",
      "Degree: 3, K: 10, Score: -2.108872865216656\n",
      "Degree: 4, K: 2, Score: -8.390351365534126\n",
      "Degree: 4, K: 3, Score: -10.368692273510527\n",
      "Degree: 4, K: 4, Score: -11.781557623280445\n",
      "Degree: 4, K: 5, Score: -11.335020483312457\n",
      "Degree: 4, K: 6, Score: -14.529025551213808\n",
      "Degree: 4, K: 7, Score: -13.582497629344761\n",
      "Degree: 4, K: 8, Score: -17.23180018854652\n",
      "Degree: 4, K: 9, Score: -13.25380717714484\n",
      "Degree: 4, K: 10, Score: -14.877095852218087\n",
      "Degree: 5, K: 2, Score: -21.411526390540192\n",
      "Degree: 5, K: 3, Score: -19.275702451325465\n",
      "Degree: 5, K: 4, Score: -18.509626126732524\n",
      "Degree: 5, K: 5, Score: -21.359915538246323\n",
      "Degree: 5, K: 6, Score: -25.096000984635037\n",
      "Degree: 5, K: 7, Score: -24.780548406629155\n",
      "Degree: 5, K: 8, Score: -29.762731983849747\n",
      "Degree: 5, K: 9, Score: -25.99651577738562\n",
      "Degree: 5, K: 10, Score: -22.811145470013955\n",
      "Degree: 6, K: 2, Score: -129.15981313387582\n",
      "Degree: 6, K: 3, Score: -101.62484326934982\n",
      "Degree: 6, K: 4, Score: -96.5293784971354\n",
      "Degree: 6, K: 5, Score: -98.44174320877906\n",
      "Degree: 6, K: 6, Score: -114.56953256107802\n",
      "Degree: 6, K: 7, Score: -119.92747229838935\n",
      "Degree: 6, K: 8, Score: -133.9410752926092\n",
      "Degree: 6, K: 9, Score: -100.06496589638839\n",
      "Degree: 6, K: 10, Score: -101.38835613866743\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_12988\\630052215.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[0mmax_k\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m10\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     59\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 60\u001B[1;33m \u001B[0mbest_degree\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbest_score\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbest_k\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfind_best_degree\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmin_degree\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmax_degree\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmin_k\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmax_k\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     61\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"Best degree: {best_degree}\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_12988\\630052215.py\u001B[0m in \u001B[0;36mfind_best_degree\u001B[1;34m(X, y, min_degree, max_degree, min_k, max_k, random_state)\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     30\u001B[0m                 \u001B[1;31m# 모델 학습\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 31\u001B[1;33m                 \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     32\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     33\u001B[0m                 \u001B[1;31m# 검증 세트의 점수 계산\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    716\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_residues\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvstack\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mout\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mouts\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    717\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 718\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcoef_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_residues\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrank_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msingular_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlinalg\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlstsq\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    719\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcoef_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcoef_\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mT\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    720\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_basic.py\u001B[0m in \u001B[0;36mlstsq\u001B[1;34m(a, b, cond, overwrite_a, overwrite_b, check_finite, lapack_driver)\u001B[0m\n\u001B[0;32m   1211\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mreal_data\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1212\u001B[0m                 \u001B[0mlwork\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0miwork\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_compute_lwork\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlapack_lwork\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mm\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnrhs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcond\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1213\u001B[1;33m                 x, s, rank, info = lapack_func(a1, b1, lwork,\n\u001B[0m\u001B[0;32m   1214\u001B[0m                                                iwork, cond, False, False)\n\u001B[0;32m   1215\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# complex data\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np\n",
    "\n",
    "def find_best_degree(X, y, min_degree, max_degree, min_k, max_k, random_state=42):\n",
    "    results = []\n",
    "    best_degree = None\n",
    "    best_score = -np.inf\n",
    "    best_k = None\n",
    "\n",
    "    for degree in range(min_degree, max_degree+1):\n",
    "        # 다항 특성 추가\n",
    "        poly = PolynomialFeatures(degree=degree)\n",
    "        X_poly = poly.fit_transform(X)\n",
    "\n",
    "        for k in range(min_k, max_k+1):\n",
    "            # 모델 학습\n",
    "            model = LinearRegression()\n",
    "\n",
    "            # k-fold 교차 검증 수행\n",
    "            kf = KFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "            score_arr = []\n",
    "\n",
    "            for train_index, test_index in kf.split(X_poly):\n",
    "                # 훈련 세트, 검증 세트 나누기\n",
    "                X_train, X_test = X_poly[train_index], X_poly[test_index]\n",
    "                y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "                # 모델 학습\n",
    "                model.fit(X_train, y_train)\n",
    "\n",
    "                # 검증 세트의 점수 계산\n",
    "                score = model.score(X_test, y_test)\n",
    "                score_arr.append(score)\n",
    "\n",
    "            # 평균 점수 계산\n",
    "            mean_score = np.mean(score_arr)\n",
    "            results.append((degree, k, mean_score))\n",
    "            print(f\"Degree: {degree}, K: {k}, Score: {mean_score}\")\n",
    "\n",
    "            # 현재 degree와 k 값의 점수가 최고 점수보다 높으면 업데이트\n",
    "            if mean_score > best_score:\n",
    "                best_degree = degree\n",
    "                best_score = mean_score\n",
    "                best_k = k\n",
    "\n",
    "    # for degree, k, score in results:\n",
    "    #     print(f\"Degree: {degree}, K: {k}, Score: {score}\")\n",
    "    return best_degree, best_score, best_k\n",
    "\n",
    "X = df_selected.drop(['visitor'], axis=1)\n",
    "y = df_selected['visitor']\n",
    "\n",
    "min_degree = 2\n",
    "max_degree = 6\n",
    "min_k = 2\n",
    "max_k = 10\n",
    "\n",
    "best_degree, best_score, best_k = find_best_degree(X, y, min_degree, max_degree, min_k, max_k)\n",
    "\n",
    "print(f\"Best degree: {best_degree}\")\n",
    "print(f\"Best score: {best_score}\")\n",
    "print(f\"Best k: {best_k}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
